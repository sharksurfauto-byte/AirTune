ğŸµ AirTune â€“ Hand Gesture Controlled Musical Instrument

AirTune is a real-time, computer visionâ€“based musical instrument that allows users to create music using hand gestures captured through a webcam. Built using Python, MediaPipe, OpenCV, and Pygame, this project detects hand landmarks and maps specific finger movements to musical notes, enabling an interactive and touchless music experience.

The system tracks hand positions in real time, identifies finger gestures, and triggers corresponding audio samples, effectively turning hand movements into sound. This project demonstrates the practical application of computer vision, gesture recognition, and humanâ€“computer interaction in an intuitive and creative way.

âœ¨ Features

Real-time hand tracking using MediaPipe

Gesture-based sound triggering

Multi-finger detection with state control

Low-latency audio playback

Simple and extendable architecture

ğŸ› ï¸ Tech Stack

Python

OpenCV

MediaPipe

Pygame

ğŸ¯ Use Cases

Gesture-controlled music creation

Interactive installations

Humanâ€“computer interaction demos

Educational projects in computer vision

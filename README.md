ðŸŽ¹ AirTune â€“ Gesture-Controlled Virtual Synthesizer

AirTune is a real-time, gesture-controlled virtual musical instrument built using Computer Vision and Digital Sound Synthesis.
It allows users to play musical notes in the air using hand gestures, without touching any physical keys or controllers.

The system uses a webcam to track hand movements and converts finger gestures into musical notes in real time, functioning like a virtual piano/synthesizer.

âœ¨ Key Features

ðŸŽ¥ Real-time hand tracking using MediaPipe

ðŸŽ¶ Synth-based sound generation (no audio samples required)

ðŸŽ¹ Two-hand support with independent note mapping

ðŸ”„ Live mode switching (Piano / Synth)

ðŸŽ§ Sustained notes while fingers are held down

ðŸ§  Gesture-based interaction â€” no keyboard or mouse needed

âš¡ Real-time performance with low latency

ðŸ§  How It Works

Hand Detection
Uses MediaPipe to detect 21 landmarks on each hand in real time.

Gesture Interpretation
Each finger is mapped to a musical note.
A note is triggered when the finger bends downward.

Sound Generation

Synth mode: Generates sine waves in real time using NumPy

Piano mode: Plays pre-recorded piano samples

Live Audio Engine
Audio is generated and controlled using pygame.mixer, allowing continuous sustain while a finger is held.

Visual Feedback
Hand landmarks and note positions are rendered live on the camera feed.

ðŸŽ¹ Controls
Action	Control
Play notes	Raise/lower fingers
Switch to Piano	Press P
Switch to Synth	Press S
Exit	ESC
ðŸ§© Technologies Used

Python

OpenCV â€“ Real-time video processing

MediaPipe â€“ Hand landmark detection

Pygame â€“ Audio synthesis & playback

NumPy â€“ Signal generation

ðŸš€ Features Implemented

Real-time gesture recognition

Polyphonic audio output

Custom sine-wave synthesizer

Sample-based piano mode

Hand-based note mapping

Stable real-time performance

ðŸ”® Future Enhancements

Velocity-sensitive dynamics

ADSR envelope control

MIDI export

Visual piano UI

Chord recognition

Effects (reverb, delay, filters)

ðŸ§  Why This Project Matters

This project combines computer vision, digital signal processing, and humanâ€“computer interaction into one system. It demonstrates real-world applications of AI and signal processing in creative technology.
